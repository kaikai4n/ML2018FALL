\documentclass[12pt, a4paper]{article}

\usepackage{xeCJK, float, graphicx, indentfirst, amsmath, amssymb, physics, multirow, caption, hyperref}
\usepackage[left=0.5in, right=0.5in]{geometry}

\setCJKmainfont{標楷體}

\author{資工四 B04902131 黃郁凱}
\title{\vspace{-2cm} Homework 3 Report - \\Image Sentiment Classification}

\begin{document}

\maketitle

\begin{enumerate}
\item 請說明你實作的 CNN model，其模型架構、訓練過程和準確率為何？\\
我主要使用三種類別的CNN模型架構，分別是仿Mobilenet、仿VGG和Kai3。
使用原本的Mobilenet與VGG的成效不好，validation大約$60\%$，因此都有做不少的變形。
以下是我的模型架構table\ref{tab:model_architecture}\\
\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|}\hline
    model&Mobilenet & VGG&Kai3\\ \hline
    \multirow{12}{*}{Convolution Block}&conv\_bn(  1,  16, 1)&conv\_bn(1,16,1)&conv\_bn(  1,  16, 1)\\
    &conv\_bn( 16,  32, 1)&conv\_bn(16,32,1)&conv\_bn(16,16,1)\\
    &conv\_bn( 32,  32, 2)&max\_pool&conv\_bn(16,32,1)\\
    &conv\_dw( 32,  64, 1)&conv\_bn(32,64,1)&max\_pool\\
    &conv\_dw( 64,  64, 1)&conv\_bn(64,64,1)&conv\_bn(32,64,1)\\
    &conv\_dw( 64, 128, 2)&max\_pool&conv\_bn(64,64,1)\\
    &conv\_dw(128, 256, 2)&conv\_bn(64,128,1)&conv\_bn(64,128,1)\\
    &conv\_dw(256, 512, 2)&conv\_bn(128,128,1)&max\_pool\\ 
    &                     &max\_pool&conv\_bn(128,256,1)\\
    &                     &conv\_bn(128,256,1)&max\_pool\\
    &                     &conv\_bn(256,256,1)&conv\_bn(128,256,1)\\
    &                     &max\_pool&max\_pool\\ \hline
    \multirow{5}{*}{Linear Block}&linear(512*3*3, 512)&linear(256*3*3,256)&linear(512*3*3, 512)\\
    &relu()&relu()&BatchNorm1d(512)\\
    &linear(512, 7)&linear(256,32)&relu()\\
    &&relu()&linear(512, 7)\\
    &&linear(32, 7)&\\ \hline
\end{tabular}
\caption{表格中的conv\_bn是一般convolution的基本架構，詳細在figure \ref{fig:conv_bn}，而conv\_dw是depthwise convolution，也就是Mobilenet提出的特殊結構，由兩個convolution組成，在figure \ref{fig:conv_dw}有詳細內容。表格左方兩者為仿造Mobilenet和VGG16建造的模型，最終可以得到約$66\%$的表現。表格右方為Kai3模型的架構，經過前面Mobilenet和VGG的經驗，我設計出在這個task上更適合的模型，前段filter數少的部分多一些層數，後半段filter數大的層數少，總共四個max pool，flatten後再接到linear輸出。此模型最終可以達到$69\%$的正確率，又比前兩者高了$3\%$。}
\label{tab:model_architecture}
\end{table}

\begin{figure}[h]
    \begin{align*}
        conv\_bn(in,out,stride) &= Sequetial(\\
        &Conv2d(in, out, 3, stride, 1),\\
        &BatchNorm2d(out),\\
        &relu())
    \end{align*}
    \caption{The basic batchnorm convolution block.}
    \label{fig:conv_bn}
\end{figure}

\begin{figure}[h]
    \begin{align*}
        conv\_bn(in,out,stride) &= Sequetial(\\
        &Conv2d(in, out, 3, stride, 1, groups=in),\\
        &BatchNorm2d(out),\\
        &relu(),\\
        &Conv2d(in, out, 1, 1, 0),\\
        &BatchNorm2d(out),\\
        &relu())
    \end{align*}
    \caption{The basic depth-wise convolution block.}
    \label{fig:conv_dw}
\end{figure}
Mobilenet和VGG16在Convolutional Block的部分和我調整過後有些微差異，他們在深度上更深，並在前半的filter數量較少，後半較多；我調整後將深度減少，並在前半段filter少的部分多做幾層，後半段大的filter層數減少。經過如此調整，正確率可以從原本的$60\%$進步到$66\%$。\\
由於Mobilenet和VGG都是用來訓練Imagenet專用的模型架構，Imagenet有一百多萬張相片，分類目標有1000個class；相比我們的task規模較小，兩萬多張相片分類7個class。人臉表情辨識的模型不需要如他們一樣龐大的模型，精簡的就可以達到很好的效果。因此經過前人模型的經驗，我自己研發了一套Kai3模型可以達到$69\%$準確率。\par
訓練過程使用batch size 128，learning rate 0.0005。兩者參數均調整過，batch size過大過小都效果不好；而learning rate=0.0005的準確率表現比0.001來得好，而更低的learning rate又會訓練過慢，所以我選用0.0005。\par
我額外將Kai3模型做了細微變形，有Kai, Kai2, Kai4模型。最終準確率如table\ref{tab:accuracy}。
\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|} \hline
        model name&validation&testing\\ \hline
        DNN&0.400&0.416\\ \hline
        Mobilenet&0.666&0.660\\ \hline
        VGG&0.662&0.667\\ \hline
        Kai&0.655&0.675\\ \hline
        Kai2&0.668&0.671\\ \hline
        Kai3&0.685&0.690\\ \hline
        Kai4&0.670&0.681\\ \hline
        ensemble&-&\textbf{0.702}\\ \hline
    \end{tabular}
    \caption{不同模型的正確率，validation切9:1，testing為kaggle分數。}
    \label{tab:accuracy}
\end{table}

\item 承上題，請用與上述 CNN 接近的參數量，實做簡單的 DNN model，其模型架構、訓練過程和準確率為何？試與上題結果做比較，並說明你觀察到了什麼？\\
在table\ref{tab:accuracy}中可以看出，DNN架構明顯表現很差，大約$40\%$正確率而已，模型架構為多層的fully connected linear layers，activation function一樣是ReLU，訓練hyperparameters如同CNN的所有模型。因為DNN比較難區別小區塊內的特徵，不像CNN有3*3或5*5的filter，當遇到相似圖形特徵就會被激發，這就是CNN模型會勝過DNN的直觀解釋。另外，CNN使用參數的效率比DNN來得好，DNN在每個pixel上都要有一個相對應的參數，而CNN則是同一塊filter重複利用，會使得DNN模型較厚重，參數使用效率不佳，在差不多參數的情況下，表現自然會比較糟。

\item 觀察答錯的圖片中，哪些 class 彼此間容易用混？ 並說明你觀察到了什麼？ [繪出 confusion matrix 分析]\\
我用正確率最高的模型Kai3，切train:validation = 9:1，train完的模型在validation上的表現畫成confusion matrix如圖figure \ref{fig:confusion_matrix}。\par
最明顯的是disgust這個class完全分類不出來，原因是training data的比例有明顯的少，所佔的比例只有$1.5\%$，因為每筆資料答錯被懲罰所占的比重都一樣，所以模型選擇直接放棄判斷這類型的class，要改善此問題有兩個方法，第一是增加這部分的training data，使他的比重和其他種類的差不多，第二是增加犯錯懲罰的比重，加在loss當中，讓模型知道要特別注重這個class。\par
另外可以發現，沿著斜對角線的格子會對稱，同時錯很多或同時錯很少。例如sad和neutral、fear和sad、surprise和fear，都是同會有將近$10\%$的比例會混淆，而happy和angry、sad和surprise就幾乎不會混淆。這個結果很合乎常理，因為快樂和生氣或是悲傷和驚訝都是反差很大的表情，機器應該可以輕易分別這個不同；相反的，傷心害怕都是臉部表情比較不激烈的肢體語言，機器要分辨就會難度變高許多，因此混淆率增加是合理的。
\begin{figure}[h]
    \centering
    \includegraphics[scale=0.8]{./confusion_matrix_normalized.png}
    %\includegraphics[width=0.42\paperwidth]{./confusion_matrix_normalized.png}
    %\includegraphics[width=0.42\paperwidth]{./confusion_matrix_origin.png}
    \caption{圖是normalize過後的比例，表示Kai3模型在validation set上的表現，y軸是正確的label，x軸是模型的預測，顏色越深代表比例越重。}
    \label{fig:confusion_matrix}
\end{figure}

\item CNN time/space complexity: For a. b. Given a CNN model as\par
%\begin{figure}[h]
%    \centering
    \includegraphics{./q4.png}\par
%\end{figure}\\
And for the c. given the parameter as:
kernel size = (k,k);
channel size = c;
input shape of each layer = (n,n);
padding = p;
strides = (s,s);
\begin{enumerate}
    \item How many parameters are there in each layer?\\
    如果不考慮bias的話，考慮的話要再加上filter數量的參數。
    \begin{enumerate}
        \item Layer A: 2*2*5*6  = 120
        \item Layer B: 2*2*6*4  = 96
    \end{enumerate}
    \item How many multiplications/additions are needed for a forward pass(each layer).(hint:不用考慮bias)\\
    \begin{enumerate}
        \item Layer A: \\
        multiply: 3*3*(2*2*5) * 6 = 1080\\
        addition: 3*3*(2*2*5-1) * 6 = 1026\\
        \item Layer B: \\
        multiply: 1*1*(2*2*6) * 4 = 96\\
        addition: 1*1*(2*2*6-1) * 4 = 92\\
    \end{enumerate}
    \item What is the time complexity of convolutional neural networks?\\
    \begin{itemize}
        \item For one layer:\par
        output size: $(\lfloor\frac{n-k+2p}{s}\rfloor + 1)^2\cdot c_{out} \leq (\frac{n-k+2p}{s}+1)^2\cdot c_{out}$\par
        total multiplication and addition $= output\_size \cdot (k^2 + k^2-1) \cdot c_{in} \leq (\frac{n-k+2p}{s}+1)^2\cdot c_{out} \cdot 2(k^2) \cdot c_{in}$\par
        time complexity is $O((\frac{n-k+2p}{s})^2 c_{in} c_{out} k^2)$.\par
        \item Total Layers:\par
        time complexite is $O(\sum\limits^l_{i=2}(\frac{n_i-k_i+2p_i}{s_i})^2 c_{i-1} c_{i} k_i^2)$.
    \end{itemize}
    \iffalse
        1 + s*(time-1) + k-1 >= n, 1 + s*(time-2) + k-1 < n
        (n-k) / s + 2 > time >= (n-k) / s + 1
        time = upper((n-k)/s) + 1
        add padding:
        time = upper((n-k+2p)/s) + 1
    \fi
\end{enumerate}

\item PCA practice:Problem statement: Given 10 samples in 3D space.\\
(1,2,3), (4,8,5), (3,12,9), (1,8,5), (5,14,2), (7,4,1), (9,8,9), (3,8,1), (11,5,6), (10,11,7)\\
\begin{enumerate}
    \item What are the principal axes?\\
    Calculate step by step:
    \begin{enumerate}
        \item input
        \begin{align*}X = array([&[ 1,  2,  3],\\
       &[ 4,  8,  5],\\
       &[ 3, 12,  9],\\
       &[ 1,  8,  5],\\
       &[ 5, 14,  2],\\
       &[ 7,  4,  1],\\
       &[ 9,  8,  9],\\
       &[ 3,  8,  1],\\
       &[11,  5,  6],\\
       &[10, 11,  7]])\end{align*}
       \item covariance matrix\\
       \begin{align*}
            Cov = array([&[1.486, 0.061 , 0.404],\\
                   &[0.061 , 1.506, 0.358],\\
                   &[0.404, 0.358, 1.007]])
       \end{align*}
       \item eigen value and eigen vector\\
       \begin{align*}
            eigen\_value = array(&[0.675, 1.435, 1.888])\\
            eigen\_vector = array([&[ 0.399, -0.678, -0.616],\\
            &[ 0.337,  0.734, -0.588],\\
            &[-0.852, -0.027, -0.522]])
       \end{align*}
    \item principle axis 1: the axis with the largest eigen value $1.888$\\
    $[-0.616, -0.588, -0.522]$\\
    principle axis 2: the axis with the second largest eigen value $1.435$\\
    $[-0.678,0.734,-0.027]$\\
    principle axis 3: the last axis with eigen value $0.675$\\
    $[0.399,0.337,-0.852]$
    \end{enumerate}
    \item Compute the principal components for each sample.\\
    principle component is the eigen vector sorted with eigen value:
    $\begin{bmatrix}
        -0.616&-0.588&-0.522\\
        0.678&-0.734&0.027\\
        0.399&0.337&-0.852\\
    \end{bmatrix}$
    \item Reconstruction error if reduced to 2D.(Calculate the L2-norm)\\
    \begin{align*}
        Loss &= \frac{min(eigen\_values)}{\sqrt{\sum\limits^3_{i=1}eigen\_value_i^2}}\\
        &= \frac{0.675}{\sqrt{0.675^2+1.435^2+1.888^2}}\\
        &= 0.273\\
    \end{align*}
\end{enumerate}

\end{enumerate}

\end{document}
